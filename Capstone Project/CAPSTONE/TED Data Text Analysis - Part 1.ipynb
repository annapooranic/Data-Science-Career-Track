{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mining TED Talk Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from contraction import CONTRACTION_MAP\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing TED data and TED Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = pd.read_csv('transcripts.csv')\n",
    "ted = pd.read_csv('ted_main.csv')\n",
    "ted_new = ted[['main_speaker','related_talks','tags','title','url']]\n",
    "data = pd.merge(transcript,ted_new,on='url')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangling before Mining\n",
    "\n",
    "  Data Wrangling is an important process before applying machine learning algorithmns. Especially for text below are the major Data Wrangling steps. They are\n",
    "\n",
    "- Removing Accented characters\n",
    "- Expanding Contractions\n",
    "- Removing Special Characters\n",
    "- Removing Stop Words\n",
    "- Lemmatization\n",
    "- Stemming\n",
    "- Removing unnecessary White spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Accented Characters\n",
    "\n",
    "Accented Charcters are the characters have accents or symbols above them. Replacing them with normal charcters is important before analysis. Examples of accented charcters are á, à, â, é, è, ê, í, ì, î, ó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding Contractions\n",
    "\n",
    "Contractions are common in English Language. Contractions are like aren't,isn't,they've,they're . For Semantic analysis expanding them help to identify the negation effects in text and negative sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Special Characters\n",
    "\n",
    "TED Scripts are the text from a talk, there is a chance for several special charcters. Removing the special chaarcters are essential for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "\n",
    "Lemmatization consider the morphological forms of words. Example lemmatozation consider 'studies','studies','studying' are considered as the root word 'study'. This helps to identify all these words as a single word and finding frequency based on them, instead of considering each as separate identity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing White Spaces\n",
    "\n",
    "While typo there are lot of chances for having unwanted white spaces.sometimes words with and without spaces are considered as different words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_whitespace(x):\n",
    "    try:\n",
    "        # remove spaces inside and outside of string\n",
    "        x = \" \".join(x.split())\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying all the functions to the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript['transcript_clean'] = transcript.transcript.apply(remove_accented_chars)\n",
    "transcript['transcript_clean'] = transcript.transcript_clean.apply(expand_contractions)\n",
    "transcript['transcript_clean'] = transcript.transcript_clean.apply(remove_special_characters)\n",
    "transcript['transcript_clean'] = transcript.transcript_clean.apply(remove_whitespace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stopwords\n",
    "\n",
    "Text contains stopwords like 'the','an,'he','is','was' those words are just fillers, but when analysing sentiments those words does not have any impact so those can be removed. For current analysis the words 'no' and 'not' are removed from stopwords list as they will clearly identify the neagtive sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf-idf Vectorization\n",
    "\n",
    "The Input type that machine learning algorithms understand are the numeric vectors, so it is necessary to convert texts into numneric vectors. tf-idf stands for Term Freqency - Inverse Document Frequency. Term frequency gives the frequency of the word in each document.It is the ratio of number of times the word appears in a document compared to the total number of words in that document. Inverse Document Frequency used to calculate the weight of rare words across all documents in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2467, 59850)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "Text=transcript['transcript_clean'].tolist()\n",
    "\n",
    "tfidf=text.TfidfVectorizer(input=Text,stop_words=stopword_list)\n",
    "\n",
    "matrix=tfidf.fit_transform(Text)\n",
    "print(matrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations\n",
    "\n",
    "Inorder to generate recommendations for each talk, we need to find the similarity between the talks. There are several similarity measures available most prominent are Jaccard,Cosine,Euclidean distance and Manhattan distance.\n",
    "\n",
    "Cosine similarity metric finds the normalized dot product of the two attributes. By determining the cosine similarity, we would effectively try to find the cosine of the angle between the two objects. The cosine of 0° is 1, and it is less than 1 for any other angle.\n",
    "\n",
    "It is thus a judgement of orientation and not magnitude: two vectors with the same orientation have a cosine similarity of 1, two vectors at 90° have a similarity of 0, and two vectors diametrically opposed have a similarity of -1, independent of their magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similar =cosine_similarity(matrix)\n",
    "similar_df = pd.DataFrame(similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_articles(x):\n",
    "    return \",  \".join(data['title'].loc[x.argsort()[-5:-1]])\n",
    "data['similar_talks']=[get_similar_articles(x) for x in similar]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New column similar_talks is generated containing three related talks for each talk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recommended talks for title: My wish: Help me stop pandemics are \n",
      "\n",
      " HIV and flu -- the vaccine strategy,  Lessons from the 1918 flu,  How we'll stop polio for good,  The case for optimism \n"
     ]
    }
   ],
   "source": [
    "#data['title','similar_talks'][12]\n",
    "\n",
    "print (\"The recommended talks for title: {} are \\n\\n {} \".format(data['title'][12],data['similar_talks'][12]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recommended talks for title: Averting the climate crisis are \n",
      "\n",
      " Design and discovery,  A one-man world summit,  A climate solution where all sides can win,  New thinking on the climate crisis \n"
     ]
    }
   ],
   "source": [
    "print (\"The recommended talks for title: {} are \\n\\n {} \".format(data['title'][1],data['similar_talks'][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling\n",
    "\n",
    "As for TED data is concern there already exists tags and categories to group the talks,what if there are no categories or search tags. Topic Modelling provides methods to organize, understand and summarize laarge collection of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA\n",
    "LDA is most widdely used technique. LDA stands for Latent Dirichlet Allocation. It uses two probability values: P( word | topics) and P( topics | documents). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=stopword_list,\n",
    "                        use_idf=True,\n",
    "                        ngram_range=(1,1), # considering only 1-grams\n",
    "                        min_df = 0.05,     # cut words present in less than 5% of documents\n",
    "                        max_df = 0.3)      # cut words present in more than 30% of documents \n",
    "\n",
    "tfidf = vectorizer.fit_transform(transcript['transcript_clean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sivakumar\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: ['women', 'brain', 'music', 'data', 'water'],\n",
       " 1: ['god', 'book', 'building', 'creativity', 'writing'],\n",
       " 2: ['ca', 'language', 'ok', 'community', 'audience'],\n",
       " 3: ['universe', 'stars', 'earth', 'planet', 'space'],\n",
       " 4: ['song', 'oh', 'music', 'film', 'yeah'],\n",
       " 5: ['god', 'force', 'education', 'push', 'oh'],\n",
       " 6: ['design', 'ok', 'designers', 'building', 'music'],\n",
       " 7: ['happiness', 'fuel', 'happy', 'design', 'waste'],\n",
       " 8: ['news', 'god', 'answers', 'google', 'dollars'],\n",
       " 9: ['music', 'ends', 'starts', 'africa', 'black']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "n_topics = 10\n",
    "lda = LatentDirichletAllocation(n_components=n_topics,random_state=0)\n",
    "\n",
    "topics = lda.fit_transform(tfidf)\n",
    "top_n_words = 5\n",
    "t_words, word_strengths = {}, {}\n",
    "for t_id, t in enumerate(lda.components_):\n",
    "    t_words[t_id] = [vectorizer.get_feature_names()[i] for i in t.argsort()[:-top_n_words - 1:-1]]\n",
    "    word_strengths[t_id] = t[t.argsort()[:-top_n_words - 1:-1]]\n",
    "t_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF\n",
    "NMF stands for Non-negative Matrix Factorization that factors high-dimensional vectors into a low-dimensionality representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ['god', 'book', 'stories', 'oh', 'art'],\n",
       " 2: ['music', 'play', 'sound', 'song', 'ends'],\n",
       " 3: ['women', 'men', 'girls', 'woman', 'sex'],\n",
       " 4: ['brain', 'brains', 'cells', 'body', 'activity'],\n",
       " 5: ['water', 'earth', 'planet', 'ocean', 'species'],\n",
       " 6: ['countries', 'africa', 'government', 'global', 'dollars'],\n",
       " 7: ['cancer', 'cells', 'patients', 'disease', 'cell'],\n",
       " 8: ['kids', 'children', 'education', 'students', 'teachers'],\n",
       " 9: ['city', 'design', 'cities', 'building', 'buildings'],\n",
       " 10: ['data', 'information', 'computer', 'machine', 'internet']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "n_topics = 10\n",
    "nmf = NMF(n_components=n_topics,random_state=0)\n",
    "\n",
    "topics = nmf.fit_transform(tfidf)\n",
    "top_n_words = 5\n",
    "t_words, word_strengths = {}, {}\n",
    "for t_id, t in enumerate(nmf.components_):\n",
    "    t_words[t_id + 1] = [vectorizer.get_feature_names()[i] for i in t.argsort()[:-top_n_words - 1:-1]]\n",
    "    word_strengths[t_id + 1] = t[t.argsort()[:-top_n_words - 1:-1]]\n",
    "t_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic distribution for document #8: \n",
      " [[0.06924094 0.00939016 0.         0.0490575  0.02995617 0.00534906\n",
      "  0.         0.03283779 0.01871856 0.01609445]]\n",
      "Relevant topics for document #8: \n",
      " [0 3 4 7 8 9]\n",
      "\n",
      "Transcript:\n",
      " It's wonderful to be back. I love this wonderful gathering. And you must be wondering, \"What on earth? Have they put up the wrong slide?\" No, no. Look at this magnificent beast, and ask the question: Who designed it?This is TED; this is Technology, Entertainment, Design, and there's a dairy cow. It's a quite wonderfully designed animal. And I was thinking, how do I introduce this? And I thought, well, maybe that old doggerel by Joyce Kilmer, you know: \"Poems are made by fools like me, but only G ...\n",
      "\n",
      "True tags from ted_main.csv: \n",
      " 8    ['God', 'TED Brain Trust', 'atheism', 'brain',...\n",
      "Name: tags, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([\n",
    "    ('tfidf', vectorizer),\n",
    "    ('nmf', nmf)\n",
    "])\n",
    "\n",
    "document_id = 8\n",
    "t = pipe.transform([transcript['transcript'].iloc[document_id]]) \n",
    "print('Topic distribution for document #{}: \\n'.format(document_id),t)\n",
    "print('Relevant topics for document #{}: \\n'.format(document_id),np.where(t>0.01)[1])\n",
    "print('\\nTranscript:\\n',transcript['transcript'].iloc[document_id][:500],'...')\n",
    "\n",
    "talk = ted[ted['url']==transcript['url'].iloc[document_id]]\n",
    "print('\\nTrue tags from ted_main.csv: \\n',talk['tags'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  According to NMF relavant topics for the above talk are 0__,3,4,7,8,9__. The __0th topic according to NMF is 'god','book','art','stories' and 3rd topic is 'brain','cell','body','activity'___ which are relavant to the tags given in __tags__ column __'God','atheism','brain'__ . \n",
    "\n",
    ">  According to LDA relavant topic for above talk is __topic 0 that is 'women','brain','music','data','water' but actual tags are 'God','atheism','brain'__\n",
    "\n",
    ">  So __NMF performs better than LDA__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic distribution for document #8: \n",
      " [[0.93190255 0.00756637 0.00756637 0.00756637 0.00756637 0.00756637\n",
      "  0.00756637 0.00756637 0.00756637 0.00756652]]\n",
      "Relevant topics for document #8: \n",
      " [0]\n",
      "\n",
      "Transcript:\n",
      " It's wonderful to be back. I love this wonderful gathering. And you must be wondering, \"What on earth? Have they put up the wrong slide?\" No, no. Look at this magnificent beast, and ask the question: Who designed it?This is TED; this is Technology, Entertainment, Design, and there's a dairy cow. It's a quite wonderfully designed animal. And I was thinking, how do I introduce this? And I thought, well, maybe that old doggerel by Joyce Kilmer, you know: \"Poems are made by fools like me, but only G ...\n",
      "\n",
      "True tags from ted_main.csv: \n",
      " 8    ['God', 'TED Brain Trust', 'atheism', 'brain',...\n",
      "Name: tags, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([\n",
    "    ('tfidf', vectorizer),\n",
    "    ('lda', lda)\n",
    "])\n",
    "\n",
    "document_id = 8\n",
    "t = pipe.transform([transcript['transcript'].iloc[document_id]]) \n",
    "print('Topic distribution for document #{}: \\n'.format(document_id),t)\n",
    "print('Relevant topics for document #{}: \\n'.format(document_id),np.where(t>0.01)[1])\n",
    "print('\\nTranscript:\\n',transcript['transcript'].iloc[document_id][:500],'...')\n",
    "\n",
    "talk = ted[ted['url']==transcript['url'].iloc[document_id]]\n",
    "print('\\nTrue tags from ted_main.csv: \\n',talk['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "total_topics = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > __pyLDAvis__ is designed to help users interpret the topics in a topic model that has been fit to a corpus of text data. The package extracts information from a fitted LDA topic model to inform an __interactive web-based visualization.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sivakumar\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:223: RuntimeWarning: divide by zero encountered in log\n",
      "  kernel = (topic_given_term * np.log((topic_given_term.T / topic_proportion).T))\n",
      "C:\\Users\\Sivakumar\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:240: RuntimeWarning: divide by zero encountered in log\n",
      "  log_lift = np.log(topic_term_dists / term_proportion)\n",
      "C:\\Users\\Sivakumar\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:241: RuntimeWarning: divide by zero encountered in log\n",
      "  log_ttd = np.log(topic_term_dists)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el24020800849725523670976737\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el24020800849725523670976737_data = {\"mdsDat\": {\"Freq\": [17.884175988199555, 3.880728948634356, 6.40542413810306, 5.753069316585506, 13.547987255142049, 14.002668509004332, 6.792837486755805, 9.292737830569818, 8.721436662501361, 13.71893386450416], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"x\": [-0.02281279019784554, -0.3177001196269325, 0.13553374724809017, -0.021651468973912544, -0.027884991461918158, 0.12747841823003517, 0.10243599411981293, 0.10372162030584355, -0.02301174999852447, -0.05610865964464889], \"y\": [-0.09323862118510488, -0.12299521012371749, -0.20656113645343746, 0.12424236313857258, 0.13302465924196932, -0.012409612114264513, 0.11575921521156103, -0.09980415153856874, 0.0712246650457272, 0.09075782877726331]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"Freq\": [189.0, 110.0, 100.0, 70.0, 78.0, 64.0, 62.0, 54.0, 72.0, 69.0, 18.255558919892035, 4.47531217267645, 5.833285839261931, 7.390770317253945, 4.1551011859033125, 14.428401718473228, 9.484757870095269, 4.797361757152342, 16.874599065547674, 13.815527183968214, 11.055001957153742, 14.512799505373755, 15.505388495314376, 16.117439084874064, 13.52575461604238, 14.777803956384151, 15.109231843702736, 189.24275536608556, 16.616327628247415, 14.501716479256578, 20.16768776086579, 6.705684365896888, 11.241484044751438, 21.91388441914987, 7.113800650877129, 3.946807831065986, 8.551407004562078, 10.625283728262113, 11.484359779816922, 12.053797096387685, 110.5729705468895, 49.625020868364395, 15.380943833699678, 29.896590886277117, 14.359233992271735, 17.95312964016555, 26.395145990241385, 10.167185187813288, 5.8101463347951965, 5.865096119340665, 12.604544455745534, 11.18236147487085, 12.070935116001621, 100.1395513473726, 16.951171266688654, 7.669681010728865, 8.374964453122937, 7.543673333758483, 7.008653162143167, 2.8112228138423587, 3.4752321601670983, 3.3339051129207493, 8.025488954634053, 6.340008534832825, 10.104915750027049, 10.975060666230345, 6.635479013374242, 33.29997300986903, 24.11836848079176, 15.532679966430527, 42.552076744752675, 22.38077383700768, 20.125774134688264, 37.380736645168675, 22.346938501861654, 14.480999556197483, 16.4002391980841, 53.24182153700917, 28.88802125349727, 24.671776081431755, 23.674384832639774, 25.032639076432623, 8.430274637232268, 12.778906721079448, 13.92088810613134, 10.718827393022034, 30.71434931671561, 6.77366335489264, 9.142861141289611, 16.41340538268639, 16.36293516317162, 25.488687464039508, 15.836717700208338, 22.14925470222871, 21.7368852578324, 15.60658663246246, 20.393519944387894, 17.443831729302627, 16.334277120145465, 70.10774204937796, 31.890013349041954, 19.57038643200591, 19.27225077043112, 51.417206970713906, 14.49143684290955, 15.838842288928694, 18.515376175254236, 27.377113122854233, 13.102609389844341, 22.389756608916734, 17.48941453223889, 19.877041499257686, 17.846874851355008, 32.20695047975475, 78.63039760999965, 25.218785252901405, 16.010606770230787, 9.306769349342733, 34.738967262266556, 35.8105673959969, 17.21407469316979, 54.19368652864094, 16.21618871069495, 21.11953914051932, 23.9725201298379, 20.302907316592695, 17.9464614259396, 23.8108139533424, 22.307383455826308, 62.937126929528524, 12.128166395313226, 42.4976316767064, 15.481508628845965, 6.973160009243969, 35.27241291192136, 43.173654019861786, 9.918994508470966, 13.806612741933982, 13.553860330412526, 19.24452746167156, 15.906423936624016, 14.754427803239045, 19.710195408109442, 71.08388939737642, 16.022663122658464, 18.867991921265023, 19.974494419554652, 42.92617035063253, 36.29138536861003, 25.736718915759447, 15.567929813056837, 13.356988230020988, 23.692745540165397, 19.412765744427162], \"Term\": [\"music\", \"women\", \"brain\", \"cancer\", \"kids\", \"city\", \"cells\", \"men\", \"data\", \"children\", \"god\", \"soul\", \"letter\", \"painting\", \"hell\", \"word\", \"writing\", \"gift\", \"book\", \"felt\", \"feeling\", \"words\", \"oh\", \"stories\", \"guy\", \"yeah\", \"art\", \"music\", \"song\", \"ends\", \"sound\", \"played\", \"playing\", \"play\", \"dance\", \"note\", \"sounds\", \"hear\", \"piece\", \"video\", \"women\", \"men\", \"gender\", \"girls\", \"female\", \"sex\", \"woman\", \"male\", \"marriage\", \"equal\", \"violence\", \"boys\", \"girl\", \"brain\", \"brains\", \"arm\", \"activity\", \"mental\", \"memory\", \"thoughts\", \"processing\", \"connections\", \"behavior\", \"visual\", \"body\", \"cells\", \"control\", \"ocean\", \"sea\", \"atmosphere\", \"earth\", \"fish\", \"solar\", \"planet\", \"ice\", \"stars\", \"sun\", \"water\", \"species\", \"universe\", \"animals\", \"energy\", \"markets\", \"governments\", \"democracy\", \"aid\", \"countries\", \"investment\", \"bank\", \"economy\", \"economic\", \"africa\", \"china\", \"government\", \"global\", \"political\", \"dollars\", \"states\", \"social\", \"cancer\", \"patients\", \"patient\", \"drug\", \"cells\", \"medicine\", \"drugs\", \"blood\", \"disease\", \"treatment\", \"cell\", \"dna\", \"health\", \"body\", \"teachers\", \"kids\", \"schools\", \"teaching\", \"grade\", \"students\", \"education\", \"teacher\", \"children\", \"teach\", \"parents\", \"child\", \"learning\", \"food\", \"buildings\", \"architecture\", \"city\", \"spaces\", \"cities\", \"urban\", \"construction\", \"building\", \"design\", \"designers\", \"cars\", \"york\", \"space\", \"project\", \"built\", \"web\", \"data\", \"machines\", \"computers\", \"digital\", \"information\", \"computer\", \"machine\", \"software\", \"google\", \"internet\", \"video\"], \"Total\": [189.0, 110.0, 100.0, 70.0, 78.0, 64.0, 62.0, 54.0, 72.0, 69.0, 18.255558919892035, 5.78000530257921, 7.936120323525528, 10.124116630465256, 5.7464535928281855, 20.030024823690372, 13.353835499190778, 6.871101246911748, 24.304827421066516, 19.90045233776155, 16.533232729982664, 22.429245487275082, 24.493553691949682, 26.975177444034145, 21.96860700727438, 24.746738089977956, 29.426224431329693, 189.24275536608556, 22.649368444267584, 19.87289058888647, 38.63944130427554, 13.696485783590484, 25.303309220723715, 49.68805985767775, 16.76455755250965, 9.453944291868886, 20.928303401446133, 27.818825501304406, 33.00255901865272, 45.549428913568576, 110.5729705468895, 54.332877189516736, 17.336124355726177, 39.147178448545375, 19.431233486667114, 24.85952615284675, 37.30465565023185, 15.853401996220754, 10.056496449146854, 10.198979141312368, 23.232752243626916, 20.487587154367667, 28.335533795574975, 100.1395513473726, 19.697650322668906, 13.007265609863301, 15.39289496363524, 14.544403402437181, 14.641473872570428, 6.313535225798799, 7.984965809959537, 8.153592186704174, 21.043147633084267, 16.982166011363372, 47.13969511400691, 62.392267636944254, 30.80116399371645, 33.29997300986903, 24.11836848079176, 15.532679966430527, 43.52495185499122, 22.93515642500892, 20.926397384790093, 39.143163550438516, 23.442376573552334, 16.382900015469293, 19.280198556442084, 65.58464483456524, 36.42580937663563, 34.145077972301465, 34.30767768642592, 42.11131372716526, 8.488537205117112, 13.60710556659613, 14.860062077958812, 11.657596662852086, 33.746064069690036, 7.631239516197447, 10.303082013063905, 18.558723493545315, 18.797769876313836, 29.413026040439846, 18.52467772982948, 27.92841869948439, 27.393209232716558, 21.14000160544425, 32.95504475133007, 25.914287403912876, 38.571956956907236, 70.10774204937796, 37.44337905925948, 23.578922781089304, 23.294545897587653, 62.392267636944254, 19.035889123820976, 21.581648454094882, 25.231045122025154, 39.546117718987574, 19.184060798858134, 35.49662934353063, 31.513353177398443, 45.610992221796394, 47.13969511400691, 32.20695047975475, 78.65653786606724, 27.009987795409224, 17.705878144881794, 11.111038016636979, 41.9924148239244, 43.426571231866184, 20.925072665632154, 69.08939196393116, 21.44723204194266, 31.7494480601719, 40.6969077992154, 34.35807643753564, 46.89830035724997, 23.8108139533424, 22.75865938124358, 64.67325537392678, 12.889159016537, 46.10287259858055, 17.300623752332154, 9.022640947746146, 46.30012354195626, 58.98035417124084, 14.048644167722024, 20.67193222944042, 24.573900723611263, 48.54682610501699, 39.03121324745842, 31.68440071609264, 19.710195408109442, 72.19842783046238, 18.077495939300025, 21.97880951969928, 23.416026146274795, 50.412255448247876, 42.86326032679817, 31.197761365027908, 19.016120538898114, 16.519260686295425, 32.795136126119054, 45.549428913568576], \"loglift\": [10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.7213, 1.4654, 1.4134, 1.4066, 1.397, 1.3932, 1.3791, 1.362, 1.3564, 1.3563, 1.3188, 1.2859, 1.264, 1.2062, 1.2362, 1.2057, 1.0547, 3.2491, 2.9394, 2.9341, 2.599, 2.535, 2.4378, 2.4305, 2.3919, 2.3756, 2.3541, 2.2867, 2.1935, 1.9197, 2.748, 2.6574, 2.6284, 2.4784, 2.4455, 2.4225, 2.4021, 2.3038, 2.1994, 2.1948, 2.1365, 2.1425, 1.8947, 2.8554, 2.7053, 2.3272, 2.2468, 2.1989, 2.1187, 2.0464, 2.0235, 1.9611, 1.8915, 1.8702, 1.3153, 1.1176, 1.3203, 1.9989, 1.9989, 1.9989, 1.9763, 1.9745, 1.9599, 1.9529, 1.9511, 1.8755, 1.8371, 1.7904, 1.7671, 1.674, 1.628, 1.4788, 1.959, 1.9031, 1.9006, 1.882, 1.8718, 1.8467, 1.8465, 1.8431, 1.8272, 1.8227, 1.8091, 1.7341, 1.7346, 1.6624, 1.486, 1.5701, 1.1067, 2.6893, 2.5288, 2.503, 2.4997, 2.4958, 2.4165, 2.3799, 2.3798, 2.3215, 2.308, 2.2285, 2.1005, 1.8587, 1.718, 2.3759, 2.3756, 2.3073, 2.2753, 2.1987, 2.1863, 2.1831, 2.1807, 2.1331, 2.0964, 1.9683, 1.8467, 1.8499, 1.4153, 2.4394, 2.4194, 2.4122, 2.3785, 2.358, 2.3283, 2.1817, 2.1673, 2.1274, 2.0913, 2.0358, 1.8444, 1.5141, 1.5417, 1.6751, 1.9864, 1.9708, 1.8657, 1.8338, 1.8274, 1.8256, 1.82, 1.794, 1.7863, 1.7739, 1.6613, 1.1335], \"logprob\": [10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.4579, -6.8638, -6.5988, -6.3621, -6.938, -5.6932, -6.1127, -6.7943, -5.5365, -5.7366, -5.9595, -5.6873, -5.6212, -5.5825, -5.7578, -5.6692, -5.647, -1.5914, -4.0241, -4.1602, -3.8304, -4.9315, -4.4149, -3.7473, -4.8724, -5.4616, -4.6884, -4.4712, -4.3935, -4.3451, -2.6299, -3.4311, -4.6025, -3.9378, -4.6712, -4.4478, -4.0624, -5.0164, -5.576, -5.5666, -4.8015, -4.9212, -4.8448, -2.6216, -4.3978, -5.1909, -5.1029, -5.2075, -5.281, -6.1946, -5.9825, -6.024, -5.1456, -5.3813, -4.9152, -4.8325, -5.3357, -4.5791, -4.9017, -5.3417, -4.3339, -4.9765, -5.0827, -4.4635, -4.978, -5.4118, -5.2874, -4.1098, -4.7213, -4.879, -4.9203, -4.8645, -5.9859, -5.5699, -5.4843, -5.7457, -4.693, -6.2046, -5.9047, -5.3196, -5.3227, -4.8795, -5.3554, -5.0199, -5.0387, -5.37, -5.1025, -5.2587, -5.3244, -3.1443, -3.932, -4.4203, -4.4356, -3.4543, -4.7208, -4.6318, -4.4757, -4.0846, -4.8215, -4.2857, -4.5327, -4.4047, -4.5125, -4.2355, -3.3429, -4.4801, -4.9344, -5.4769, -4.1598, -4.1294, -4.8619, -3.7151, -4.9217, -4.6575, -4.5308, -4.6969, -4.8203, -4.4741, -4.5393, -3.5021, -5.1487, -3.8948, -4.9046, -5.7022, -4.0811, -3.879, -5.3498, -5.0191, -5.0376, -4.687, -4.8775, -4.9527, -5.1161, -3.8334, -5.3232, -5.1597, -5.1028, -4.3377, -4.5056, -4.8493, -5.352, -5.5052, -4.932, -5.1313]}, \"token.table\": {\"Topic\": [4, 5, 6, 8, 9, 10, 3, 5, 6, 8, 6, 8, 1, 4, 5, 7, 9, 1, 4, 5, 7, 1, 2, 9, 10, 5, 6, 1, 3, 4, 5, 6, 8, 10, 1, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 3, 8, 9, 10, 1, 2, 3, 8, 4, 4, 5, 10, 2, 3, 5, 8, 9, 10, 9, 1, 5, 6, 8, 9, 10, 7, 1, 6, 9, 10, 4, 5, 7, 10, 4, 7, 1, 2, 3, 4, 6, 7, 8, 3, 4, 6, 8, 6, 9, 6, 9, 3, 9, 2, 4, 8, 10, 4, 8, 10, 1, 4, 9, 10, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 8, 1, 2, 3, 5, 7, 7, 10, 3, 6, 2, 7, 9, 10, 9, 10, 2, 6, 10, 3, 4, 6, 7, 8, 5, 7, 10, 6, 7, 8, 9, 10, 6, 7, 4, 6, 7, 1, 5, 3, 6, 9, 6, 9, 3, 6, 8, 1, 2, 5, 10, 4, 5, 6, 9, 3, 6, 8, 1, 3, 4, 1, 3, 7, 8, 9, 1, 3, 4, 5, 7, 5, 4, 5, 6, 7, 8, 9, 1, 3, 10, 1, 4, 8, 1, 2, 3, 8, 3, 8, 5, 6, 1, 1, 6, 10, 6, 9, 10, 6, 10, 1, 8, 10, 1, 8, 9, 10, 3, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 1, 5, 1, 5, 4, 6, 7, 10, 1, 2, 6, 10, 6, 8, 2, 4, 5, 8, 10, 1, 10, 2, 4, 5, 8, 10, 4, 5, 10, 1, 3, 5, 7, 6, 1, 3, 4, 2, 5, 6, 7, 10, 1, 4, 7, 10, 1, 3, 4, 1, 4, 6, 7, 8, 2, 1, 2, 4, 5, 10, 5, 1, 2, 3, 4, 10, 1, 9, 1, 3, 8, 1, 4, 6, 7, 8, 4, 7, 8, 1, 2, 4, 5, 7, 9, 10, 5, 6, 1, 2, 4, 8, 9, 10, 1, 2, 3, 4, 8, 10, 1, 2, 4, 8, 10, 1, 3, 6, 4, 10, 1, 2, 5, 7, 8, 9, 10, 6, 8, 9, 5, 1, 3, 4, 5, 7, 1, 3, 4, 6, 8, 9, 10, 2, 6, 7, 8, 10, 5, 9, 1, 2, 1, 2, 1, 2, 4, 5, 10, 1, 2, 4, 5, 10, 1, 4, 5, 9, 10, 9, 4, 5, 7, 2, 5, 10, 1, 3, 4, 6, 7, 8, 9, 1, 3, 6, 9, 8, 10, 1, 5, 9, 1, 3, 8, 10, 1, 2, 3, 8, 10, 8, 1, 8, 10, 1, 4, 1, 3, 6, 7, 8, 2, 4, 5, 10, 6, 9, 1, 2, 4, 5, 8, 10, 1, 3, 6, 9, 1, 2, 4, 9, 10, 3, 5, 8, 9, 10, 1, 3, 8, 3, 1, 3, 4, 10, 1, 4, 6, 10, 1, 3, 8, 10, 1, 2, 5, 10, 1, 3, 8, 9], \"Freq\": [0.5197203007556086, 0.06496503759445107, 0.06496503759445107, 0.06496503759445107, 0.06496503759445107, 0.06496503759445107, 0.03399854195978014, 0.06799708391956027, 0.8499635489945035, 0.03399854195978014, 0.9435907175492206, 0.08578097432265643, 0.02914799448508452, 0.1457399724254226, 0.6995518676420285, 0.11659197794033808, 0.9666650232540136, 0.3075204366524839, 0.6150408733049678, 0.07688010916312098, 0.07688010916312098, 0.5097493915675335, 0.0679665855423378, 0.339832927711689, 0.0679665855423378, 1.030086246197015, 0.873525027616819, 0.0950428155935939, 0.04752140779679695, 0.3801712623743756, 0.0950428155935939, 0.14256422339039085, 0.04752140779679695, 0.1900856311871878, 0.11890113887439344, 0.11890113887439344, 0.039633712958131145, 0.7530405462044918, 0.21213544075359617, 0.04242708815071923, 0.021213544075359615, 0.21213544075359617, 0.1272812644521577, 0.3818437933564731, 0.6994495252109889, 0.04114408971829347, 0.08228817943658694, 0.04114408971829347, 0.16457635887317387, 0.048810042513318316, 0.09762008502663663, 0.5369104676465014, 0.29286025507990987, 0.998606431270213, 0.863047100619695, 0.05076747650704089, 0.05076747650704089, 0.021598214507868856, 0.021598214507868856, 0.04319642901573771, 0.08639285803147542, 0.7559375077754099, 0.08639285803147542, 1.0079453834307517, 0.03156127234220011, 0.09468381702660034, 0.03156127234220011, 0.09468381702660034, 0.4734190851330017, 0.2524901787376009, 0.9984631932761139, 0.0483747715937181, 0.14512431478115428, 0.6772468023120534, 0.14512431478115428, 0.08451506679596212, 0.11268675572794949, 0.6197771565037222, 0.14085844465993685, 0.17630389816905107, 0.8174089824201458, 0.122859457152575, 0.04914378286103, 0.09828756572206, 0.073715674291545, 0.04914378286103, 0.024571891430515, 0.58972539433236, 0.11579201629356477, 0.043422006110086786, 0.043422006110086786, 0.7815961099815621, 0.8637127313818743, 0.10796409142273429, 0.08676248950533194, 0.9110061398059853, 0.015462342110633154, 0.9741275529698887, 0.04666000637262764, 0.06999000955894145, 0.04666000637262764, 0.8398801147072975, 0.045498369650263125, 0.045498369650263125, 0.8644690233549994, 0.1226453294574471, 0.3679359883723413, 0.2452906589148942, 0.2452906589148942, 0.11083229464537209, 0.11083229464537209, 0.7758260625176046, 0.06493261100158446, 0.03246630550079223, 0.03246630550079223, 0.2272641385055456, 0.0973989165023767, 0.1298652220031689, 0.06493261100158446, 0.03246630550079223, 0.03246630550079223, 0.2597304440063378, 0.9186256487862094, 0.0888992563341493, 0.3578979034315046, 0.41754755400342203, 0.059649650571917436, 0.059649650571917436, 0.059649650571917436, 0.013850717114619415, 0.9834009151379786, 0.06729446988537484, 0.9421225783952478, 0.016954798153579174, 0.016954798153579174, 0.7290563206039046, 0.22041237599652927, 0.7118124625133481, 0.28472498500533927, 0.04270579447397345, 0.0854115889479469, 0.854115889479469, 0.02528693226237635, 0.1011477290495054, 0.1011477290495054, 0.6827471710841615, 0.07586079678712905, 0.22212805982895023, 0.5394538595845934, 0.22212805982895023, 0.6068873567283746, 0.06068873567283745, 0.09103310350925618, 0.030344367836418727, 0.18206620701851237, 0.171714014842171, 0.8156415705003123, 0.04633566347478248, 0.2316783173739124, 0.7413706155965197, 0.022975326964901056, 0.9879390594907453, 0.05319779987625297, 0.8511647980200475, 0.05319779987625297, 0.8621282603604049, 0.10776603254505061, 0.04605475273010757, 0.11513688182526892, 0.8289855491419362, 0.10063961209138148, 0.754797090685361, 0.05031980604569074, 0.05031980604569074, 0.04749317518227496, 0.593664689778437, 0.16622611313796237, 0.18997270072909983, 0.5882941730605346, 0.19609805768684485, 0.09804902884342243, 0.6653266290779137, 0.1814527170212492, 0.12096847801416614, 0.7035015969679589, 0.15075034220741976, 0.050250114069139915, 0.050250114069139915, 0.050250114069139915, 0.0514635368200458, 0.7204895154806412, 0.0514635368200458, 0.1543906104601374, 0.0514635368200458, 0.9592260716395548, 0.02132273435033794, 0.36248648395574495, 0.12793640610202764, 0.04264546870067588, 0.3838092183060829, 0.04264546870067588, 0.05768301954235214, 0.8652452931352821, 0.05768301954235214, 0.7276853913697278, 0.14553707827394555, 0.14553707827394555, 0.24703963759783332, 0.03529137679969047, 0.4234965215962857, 0.2823310143975238, 0.7663387551527289, 0.22990162654581867, 0.2190323867870879, 0.8031187515526556, 0.9860010355742345, 0.12107079354097389, 0.06053539677048694, 0.7869601580163302, 0.787728092905101, 0.03580582240477732, 0.1790291120238866, 0.9553831956675265, 0.0734910150513482, 0.0900005920691354, 0.8100053286222186, 0.0900005920691354, 0.6372729957509019, 0.04551949969649299, 0.09103899939298599, 0.227597498482465, 0.06577361846047217, 0.28501901332871277, 0.43849078973648115, 0.19732085538141653, 0.021924539486824057, 0.3594688064573793, 0.3954156871031172, 0.07189376129147584, 0.07189376129147584, 0.03594688064573792, 0.03594688064573792, 0.03594688064573792, 0.6960814936349904, 0.1740203734087476, 0.04265779098217367, 0.9384714016078207, 0.05950933901538555, 0.0396728926769237, 0.0396728926769237, 0.8529671925538596, 0.030492326549715683, 0.030492326549715683, 0.24393861239772546, 0.7318158371931764, 0.9172821774421273, 1.0043666063019148, 0.02910523823468523, 0.08731571470405569, 0.02910523823468523, 0.5821047646937046, 0.2910523823468523, 0.7560369242656052, 0.2520123080885351, 0.03205358193171452, 0.06410716386342905, 0.03205358193171452, 0.03205358193171452, 0.8333931302245776, 0.05531739591355819, 0.05531739591355819, 0.8850783346169311, 0.06307794379013332, 0.6307794379013332, 0.18923383137039995, 0.06307794379013332, 0.9424474213504526, 0.2983146282773765, 0.596629256554753, 0.09943820942579215, 0.05253235052460083, 0.05253235052460083, 0.10506470104920165, 0.7354529073444116, 0.05253235052460083, 0.2731965398301645, 0.4780939447027879, 0.06829913495754113, 0.2048974048726234, 0.07362024996481836, 0.9202531245602296, 0.01840506249120459, 0.2750198746089322, 0.5500397492178644, 0.06875496865223304, 0.06875496865223304, 0.06875496865223304, 0.9987172276919348, 0.3173278694460077, 0.4231038259280103, 0.10577595648200258, 0.10577595648200258, 0.10577595648200258, 0.9909917942041537, 0.6532330996648614, 0.16330827491621536, 0.04082706872905384, 0.04082706872905384, 0.08165413745810768, 0.691418348435039, 0.29632214932930245, 0.18897966316229292, 0.1259864421081953, 0.6614288210680253, 0.0848215170204482, 0.0424107585102241, 0.0424107585102241, 0.8482151702044819, 0.0424107585102241, 0.0534139826652588, 0.8546237226441408, 0.0801209739978882, 0.24240544484682172, 0.33330748666437987, 0.030300680605852715, 0.06060136121170543, 0.06060136121170543, 0.15150340302926357, 0.12120272242341086, 0.945248075115929, 0.051094490546806974, 0.1408789157807772, 0.4427623067395855, 0.08050223758901554, 0.16100447517803107, 0.04025111879450777, 0.1408789157807772, 0.2190342871449731, 0.5110800033382705, 0.07301142904832436, 0.07301142904832436, 0.07301142904832436, 0.07301142904832436, 0.15808208978151964, 0.434725746899179, 0.07904104489075982, 0.15808208978151964, 0.15808208978151964, 0.09460737219078232, 0.14191105828617348, 0.7568589775262585, 0.37570605452789063, 0.5009414060371875, 0.10248208208748076, 0.05124104104374038, 0.10248208208748076, 0.02562052052187019, 0.07686156156561057, 0.40992832834992304, 0.2562052052187019, 0.037023341423722, 0.9255835355930501, 0.037023341423722, 0.9950921854069014, 0.04022602819746371, 0.7240685075543468, 0.08045205639492742, 0.08045205639492742, 0.04022602819746371, 0.05185114154914175, 0.1037022830982835, 0.07777671232371262, 0.414809132393134, 0.1296278538728544, 0.025925570774570875, 0.18147899542199614, 0.05258696157055096, 0.05258696157055096, 0.05258696157055096, 0.05258696157055096, 0.8413913851288154, 0.9557306798797854, 0.04778653399398927, 0.26490804875040846, 0.750572804792824, 0.692040887612176, 0.173010221903044, 0.18116203971162062, 0.5176058277474875, 0.1035211655494975, 0.1035211655494975, 0.07764087416212312, 0.19112872760262078, 0.43003963710589677, 0.1433465457019656, 0.09556436380131039, 0.09556436380131039, 0.08239467584033525, 0.02059866896008381, 0.3501773723214248, 0.3913747102415924, 0.1441906827205867, 0.931014970379666, 0.08235918573505385, 0.796138795438854, 0.10981224764673848, 0.061039254286833586, 0.8545495600156702, 0.061039254286833586, 0.07717750323699868, 0.07717750323699868, 0.03858875161849934, 0.6560087775144887, 0.03858875161849934, 0.03858875161849934, 0.03858875161849934, 0.5931378962453712, 0.2965689481226856, 0.0741422370306714, 0.0370711185153357, 0.833483860043681, 0.1666967720087362, 0.1037333715285697, 0.8298669722285577, 0.05186668576428485, 0.09325212671214439, 0.046626063356072195, 0.7460170136971551, 0.09325212671214439, 0.04778955925168299, 0.04778955925168299, 0.04778955925168299, 0.8124225072786109, 0.04778955925168299, 0.9935743534649504, 0.05647841873852883, 0.9036546998164613, 0.05647841873852883, 0.4751695987600093, 0.4751695987600093, 0.05212660710810099, 0.05212660710810099, 0.15637982132430298, 0.6776458924053129, 0.10425321421620198, 0.05857359592566761, 0.029286797962833806, 0.7321699490708451, 0.20500758573983663, 0.11560276835281136, 0.8670207626460852, 0.1536792044809763, 0.2634500648245308, 0.043908344137421805, 0.0658625162061327, 0.043908344137421805, 0.41712926930550714, 0.1721707337148253, 0.5595548845731823, 0.25825610057223797, 0.043042683428706326, 0.11777060703927454, 0.05888530351963727, 0.3533118211178236, 0.11777060703927454, 0.29442651759818633, 0.015247471454979466, 0.8081159871139117, 0.06098988581991786, 0.12197977163983573, 1.0147032835489456, 0.26806305609036896, 0.6969639458349592, 0.026806305609036896, 1.0038619696205902, 0.6989507064135836, 0.04992505045811311, 0.04992505045811311, 0.14977515137433933, 0.6687697099980487, 0.13375394199960974, 0.04458464733320325, 0.178338589332813, 0.6739636713770651, 0.07488485237522946, 0.07488485237522946, 0.14976970475045892, 0.6061404919493113, 0.24245619677972455, 0.04040936612995409, 0.12122809838986227, 0.28485506142190165, 0.040693580203128805, 0.08138716040625761, 0.5697101228438033], \"Term\": [\"activity\", \"activity\", \"activity\", \"activity\", \"activity\", \"activity\", \"africa\", \"africa\", \"africa\", \"africa\", \"aid\", \"aid\", \"animals\", \"animals\", \"animals\", \"animals\", \"architecture\", \"arm\", \"arm\", \"arm\", \"arm\", \"art\", \"art\", \"art\", \"art\", \"atmosphere\", \"bank\", \"behavior\", \"behavior\", \"behavior\", \"behavior\", \"behavior\", \"behavior\", \"behavior\", \"blood\", \"blood\", \"blood\", \"blood\", \"body\", \"body\", \"body\", \"body\", \"body\", \"body\", \"book\", \"book\", \"book\", \"book\", \"book\", \"boys\", \"boys\", \"boys\", \"boys\", \"brain\", \"brains\", \"brains\", \"brains\", \"building\", \"building\", \"building\", \"building\", \"building\", \"building\", \"buildings\", \"built\", \"built\", \"built\", \"built\", \"built\", \"built\", \"cancer\", \"cars\", \"cars\", \"cars\", \"cars\", \"cell\", \"cell\", \"cell\", \"cell\", \"cells\", \"cells\", \"child\", \"child\", \"child\", \"child\", \"child\", \"child\", \"child\", \"children\", \"children\", \"children\", \"children\", \"china\", \"china\", \"cities\", \"cities\", \"city\", \"city\", \"computer\", \"computer\", \"computer\", \"computer\", \"computers\", \"computers\", \"computers\", \"connections\", \"connections\", \"connections\", \"connections\", \"construction\", \"construction\", \"construction\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"countries\", \"countries\", \"dance\", \"dance\", \"dance\", \"dance\", \"dance\", \"data\", \"data\", \"democracy\", \"democracy\", \"design\", \"design\", \"design\", \"design\", \"designers\", \"designers\", \"digital\", \"digital\", \"digital\", \"disease\", \"disease\", \"disease\", \"disease\", \"disease\", \"dna\", \"dna\", \"dna\", \"dollars\", \"dollars\", \"dollars\", \"dollars\", \"dollars\", \"drug\", \"drug\", \"drugs\", \"drugs\", \"drugs\", \"earth\", \"earth\", \"economic\", \"economic\", \"economic\", \"economy\", \"economy\", \"education\", \"education\", \"education\", \"ends\", \"ends\", \"ends\", \"ends\", \"energy\", \"energy\", \"energy\", \"energy\", \"equal\", \"equal\", \"equal\", \"feeling\", \"feeling\", \"feeling\", \"felt\", \"felt\", \"felt\", \"felt\", \"felt\", \"female\", \"female\", \"female\", \"female\", \"female\", \"fish\", \"food\", \"food\", \"food\", \"food\", \"food\", \"food\", \"gender\", \"gender\", \"gender\", \"gift\", \"gift\", \"gift\", \"girl\", \"girl\", \"girl\", \"girl\", \"girls\", \"girls\", \"global\", \"global\", \"god\", \"google\", \"google\", \"google\", \"government\", \"government\", \"government\", \"governments\", \"governments\", \"grade\", \"grade\", \"grade\", \"guy\", \"guy\", \"guy\", \"guy\", \"health\", \"health\", \"health\", \"health\", \"health\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"hell\", \"hell\", \"ice\", \"ice\", \"information\", \"information\", \"information\", \"information\", \"internet\", \"internet\", \"internet\", \"internet\", \"investment\", \"kids\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"letter\", \"letter\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machines\", \"machines\", \"machines\", \"male\", \"male\", \"male\", \"male\", \"markets\", \"marriage\", \"marriage\", \"marriage\", \"medicine\", \"medicine\", \"medicine\", \"medicine\", \"medicine\", \"memory\", \"memory\", \"memory\", \"memory\", \"men\", \"men\", \"men\", \"mental\", \"mental\", \"mental\", \"mental\", \"mental\", \"music\", \"note\", \"note\", \"note\", \"note\", \"note\", \"ocean\", \"oh\", \"oh\", \"oh\", \"oh\", \"oh\", \"painting\", \"painting\", \"parents\", \"parents\", \"parents\", \"patient\", \"patient\", \"patient\", \"patient\", \"patient\", \"patients\", \"patients\", \"patients\", \"piece\", \"piece\", \"piece\", \"piece\", \"piece\", \"piece\", \"piece\", \"planet\", \"planet\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"played\", \"played\", \"played\", \"played\", \"played\", \"played\", \"playing\", \"playing\", \"playing\", \"playing\", \"playing\", \"political\", \"political\", \"political\", \"processing\", \"processing\", \"project\", \"project\", \"project\", \"project\", \"project\", \"project\", \"project\", \"schools\", \"schools\", \"schools\", \"sea\", \"sex\", \"sex\", \"sex\", \"sex\", \"sex\", \"social\", \"social\", \"social\", \"social\", \"social\", \"social\", \"social\", \"software\", \"software\", \"software\", \"software\", \"software\", \"solar\", \"solar\", \"song\", \"song\", \"soul\", \"soul\", \"sound\", \"sound\", \"sound\", \"sound\", \"sound\", \"sounds\", \"sounds\", \"sounds\", \"sounds\", \"sounds\", \"space\", \"space\", \"space\", \"space\", \"space\", \"spaces\", \"species\", \"species\", \"species\", \"stars\", \"stars\", \"stars\", \"states\", \"states\", \"states\", \"states\", \"states\", \"states\", \"states\", \"stories\", \"stories\", \"stories\", \"stories\", \"students\", \"students\", \"sun\", \"sun\", \"sun\", \"teach\", \"teach\", \"teach\", \"teach\", \"teacher\", \"teacher\", \"teacher\", \"teacher\", \"teacher\", \"teachers\", \"teaching\", \"teaching\", \"teaching\", \"thoughts\", \"thoughts\", \"treatment\", \"treatment\", \"treatment\", \"treatment\", \"treatment\", \"universe\", \"universe\", \"universe\", \"universe\", \"urban\", \"urban\", \"video\", \"video\", \"video\", \"video\", \"video\", \"video\", \"violence\", \"violence\", \"violence\", \"violence\", \"visual\", \"visual\", \"visual\", \"visual\", \"visual\", \"water\", \"water\", \"water\", \"water\", \"web\", \"woman\", \"woman\", \"woman\", \"women\", \"word\", \"word\", \"word\", \"word\", \"words\", \"words\", \"words\", \"words\", \"writing\", \"writing\", \"writing\", \"writing\", \"yeah\", \"yeah\", \"yeah\", \"yeah\", \"york\", \"york\", \"york\", \"york\"]}, \"R\": 10, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el24020800849725523670976737\", ldavis_el24020800849725523670976737_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el24020800849725523670976737\", ldavis_el24020800849725523670976737_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el24020800849725523670976737\", ldavis_el24020800849725523670976737_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=            Freq  cluster  topics         x         y\n",
       "topic                                                \n",
       "0      17.884176        1       1 -0.022813 -0.093239\n",
       "1       3.880729        1       2 -0.317700 -0.122995\n",
       "2       6.405424        1       3  0.135534 -0.206561\n",
       "3       5.753069        1       4 -0.021651  0.124242\n",
       "4      13.547987        1       5 -0.027885  0.133025\n",
       "5      14.002669        1       6  0.127478 -0.012410\n",
       "6       6.792837        1       7  0.102436  0.115759\n",
       "7       9.292738        1       8  0.103722 -0.099804\n",
       "8       8.721437        1       9 -0.023012  0.071225\n",
       "9      13.718934        1      10 -0.056109  0.090758, topic_info=     Category        Freq          Term       Total  loglift  logprob\n",
       "term                                                                 \n",
       "1033  Default  189.000000         music  189.000000  10.0000  10.0000\n",
       "1718  Default  110.000000         women  110.000000   9.0000   9.0000\n",
       "196   Default  100.000000         brain  100.000000   8.0000   8.0000\n",
       "227   Default   70.000000        cancer   70.000000   7.0000   7.0000\n",
       "873   Default   78.000000          kids   78.000000   6.0000   6.0000\n",
       "281   Default   64.000000          city   64.000000   5.0000   5.0000\n",
       "248   Default   62.000000         cells   62.000000   4.0000   4.0000\n",
       "985   Default   54.000000           men   54.000000   3.0000   3.0000\n",
       "399   Default   72.000000          data   72.000000   2.0000   2.0000\n",
       "270   Default   69.000000      children   69.000000   1.0000   1.0000\n",
       "721    Topic1   18.255559           god   18.255559   1.7213  -5.4579\n",
       "1448   Topic1    4.475312          soul    5.780005   1.4654  -6.8638\n",
       "917    Topic1    5.833286        letter    7.936120   1.4134  -6.5988\n",
       "1116   Topic1    7.390770      painting   10.124117   1.4066  -6.3621\n",
       "763    Topic1    4.155101          hell    5.746454   1.3970  -6.9380\n",
       "1723   Topic1   14.428402          word   20.030025   1.3932  -5.6932\n",
       "1737   Topic1    9.484758       writing   13.353835   1.3791  -6.1127\n",
       "711    Topic1    4.797362          gift    6.871101   1.3620  -6.7943\n",
       "188    Topic1   16.874599          book   24.304827   1.3564  -5.5365\n",
       "627    Topic1   13.815527          felt   19.900452   1.3563  -5.7366\n",
       "621    Topic1   11.055002       feeling   16.533233   1.3188  -5.9595\n",
       "1724   Topic1   14.512800         words   22.429245   1.2859  -5.6873\n",
       "1087   Topic1   15.505388            oh   24.493554   1.2640  -5.6212\n",
       "1497   Topic1   16.117439       stories   26.975177   1.2062  -5.5825\n",
       "742    Topic1   13.525755           guy   21.968607   1.2362  -5.7578\n",
       "1740   Topic1   14.777804          yeah   24.746738   1.2057  -5.6692\n",
       "115    Topic1   15.109232           art   29.426224   1.0547  -5.6470\n",
       "1033   Topic2  189.242755         music  189.242755   3.2491  -1.5914\n",
       "1443   Topic2   16.616328          song   22.649368   2.9394  -4.0241\n",
       "523    Topic2   14.501716          ends   19.872891   2.9341  -4.1602\n",
       "...       ...         ...           ...         ...      ...      ...\n",
       "268    Topic8   23.972520         child   40.696908   1.8467  -4.5308\n",
       "907    Topic8   20.302907      learning   34.358076   1.8499  -4.6969\n",
       "661    Topic8   17.946461          food   46.898300   1.4153  -4.8203\n",
       "214    Topic9   23.810814     buildings   23.810814   2.4394  -4.4741\n",
       "106    Topic9   22.307383  architecture   22.758659   2.4194  -4.5393\n",
       "281    Topic9   62.937127          city   64.673255   2.4122  -3.5021\n",
       "1456   Topic9   12.128166        spaces   12.889159   2.3785  -5.1487\n",
       "279    Topic9   42.497632        cities   46.102873   2.3580  -3.8948\n",
       "1646   Topic9   15.481509         urban   17.300624   2.3283  -4.9046\n",
       "346    Topic9    6.973160  construction    9.022641   2.1817  -5.7022\n",
       "213    Topic9   35.272413      building   46.300124   2.1673  -4.0811\n",
       "432    Topic9   43.173654        design   58.980354   2.1274  -3.8790\n",
       "434    Topic9    9.918995     designers   14.048644   2.0913  -5.3498\n",
       "240    Topic9   13.806613          cars   20.671932   2.0358  -5.0191\n",
       "1743   Topic9   13.553860          york   24.573901   1.8444  -5.0376\n",
       "1455   Topic9   19.244527         space   48.546826   1.5141  -4.6870\n",
       "1230   Topic9   15.906424       project   39.031213   1.5417  -4.8775\n",
       "215    Topic9   14.754428         built   31.684401   1.6751  -4.9527\n",
       "1693  Topic10   19.710195           web   19.710195   1.9864  -5.1161\n",
       "399   Topic10   71.083889          data   72.198428   1.9708  -3.8334\n",
       "950   Topic10   16.022663      machines   18.077496   1.8657  -5.3232\n",
       "329   Topic10   18.867992     computers   21.978810   1.8338  -5.1597\n",
       "453   Topic10   19.974494       digital   23.416026   1.8274  -5.1028\n",
       "828   Topic10   42.926170   information   50.412255   1.8256  -4.3377\n",
       "328   Topic10   36.291385      computer   42.863260   1.8200  -4.5056\n",
       "949   Topic10   25.736719       machine   31.197761   1.7940  -4.8493\n",
       "1431  Topic10   15.567930      software   19.016121   1.7863  -5.3520\n",
       "723   Topic10   13.356988        google   16.519261   1.7739  -5.5052\n",
       "847   Topic10   23.692746      internet   32.795136   1.6613  -4.9320\n",
       "1659  Topic10   19.412766         video   45.549429   1.1335  -5.1313\n",
       "\n",
       "[154 rows x 6 columns], token_table=      Topic      Freq          Term\n",
       "term                               \n",
       "45        4  0.519720      activity\n",
       "45        5  0.064965      activity\n",
       "45        6  0.064965      activity\n",
       "45        8  0.064965      activity\n",
       "45        9  0.064965      activity\n",
       "45       10  0.064965      activity\n",
       "60        3  0.033999        africa\n",
       "60        5  0.067997        africa\n",
       "60        6  0.849964        africa\n",
       "60        8  0.033999        africa\n",
       "67        6  0.943591           aid\n",
       "67        8  0.085781           aid\n",
       "91        1  0.029148       animals\n",
       "91        4  0.145740       animals\n",
       "91        5  0.699552       animals\n",
       "91        7  0.116592       animals\n",
       "106       9  0.966665  architecture\n",
       "111       1  0.307520           arm\n",
       "111       4  0.615041           arm\n",
       "111       5  0.076880           arm\n",
       "111       7  0.076880           arm\n",
       "115       1  0.509749           art\n",
       "115       2  0.067967           art\n",
       "115       9  0.339833           art\n",
       "115      10  0.067967           art\n",
       "125       5  1.030086    atmosphere\n",
       "141       6  0.873525          bank\n",
       "161       1  0.095043      behavior\n",
       "161       3  0.047521      behavior\n",
       "161       4  0.380171      behavior\n",
       "...     ...       ...           ...\n",
       "1667     10  0.294427        visual\n",
       "1688      3  0.015247         water\n",
       "1688      5  0.808116         water\n",
       "1688      8  0.060990         water\n",
       "1688      9  0.121980         water\n",
       "1693     10  1.014703           web\n",
       "1717      1  0.268063         woman\n",
       "1717      3  0.696964         woman\n",
       "1717      8  0.026806         woman\n",
       "1718      3  1.003862         women\n",
       "1723      1  0.698951          word\n",
       "1723      3  0.049925          word\n",
       "1723      4  0.049925          word\n",
       "1723     10  0.149775          word\n",
       "1724      1  0.668770         words\n",
       "1724      4  0.133754         words\n",
       "1724      6  0.044585         words\n",
       "1724     10  0.178339         words\n",
       "1737      1  0.673964       writing\n",
       "1737      3  0.074885       writing\n",
       "1737      8  0.074885       writing\n",
       "1737     10  0.149770       writing\n",
       "1740      1  0.606140          yeah\n",
       "1740      2  0.242456          yeah\n",
       "1740      5  0.040409          yeah\n",
       "1740     10  0.121228          yeah\n",
       "1743      1  0.284855          york\n",
       "1743      3  0.040694          york\n",
       "1743      8  0.081387          york\n",
       "1743      9  0.569710          york\n",
       "\n",
       "[495 rows x 3 columns], R=10, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.sklearn.prepare(nmf,tfidf,vectorizer, R=10,sort_topics=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The above visulaization shows the clusters of topics and how closely they are related. The __cluster number 2 is related to topics like music,sound,song and videos thats why it stood out.The Cluster 6 and 8 have overlap since cluster 6 topics are global,countries,economy,social etc and cluster 8 are kids,children,education,food.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
