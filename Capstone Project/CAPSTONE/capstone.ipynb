{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from contraction import CONTRACTION_MAP\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = pd.read_csv('transcripts.csv')\n",
    "ted = pd.read_csv('ted_main.csv')\n",
    "ted_new = ted[['main_speaker','related_talks','tags','title','url']]\n",
    "data = pd.merge(transcript,ted_new,on='url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript['transcript_clean'] = transcript.transcript.apply(remove_accented_chars)\n",
    "transcript['transcript_clean'] = transcript.transcript_clean.apply(expand_contractions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript['transcript_clean'] = transcript.transcript_clean.apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_whitespace(x):\n",
    "    try:\n",
    "        # remove spaces inside and outside of string\n",
    "        x = \" \".join(x.split())\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript['transcript_clean'] = transcript.transcript_clean.apply(remove_whitespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2467, 59850)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "Text=transcript['transcript_clean'].tolist()\n",
    "\n",
    "tfidf=text.TfidfVectorizer(input=Text,stop_words=stopword_list)\n",
    "\n",
    "matrix=tfidf.fit_transform(Text)\n",
    "print(matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similar =cosine_similarity(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_articles(x):\n",
    "    return \",\".join(data['title'].loc[x.argsort()[-5:-1]])\n",
    "data['similar_talks']=[get_similar_articles(x) for x in similar]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>url</th>\n",
       "      <th>main_speaker</th>\n",
       "      <th>related_talks</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>similar_talks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good morning. How are you?(Laughter)It's been ...</td>\n",
       "      <td>https://www.ted.com/talks/ken_robinson_says_sc...</td>\n",
       "      <td>Ken Robinson</td>\n",
       "      <td>[{'id': 865, 'hero': 'https://pe.tedcdn.com/im...</td>\n",
       "      <td>['children', 'creativity', 'culture', 'dance',...</td>\n",
       "      <td>Do schools kill creativity?</td>\n",
       "      <td>A one-man world summit,How to run a company wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you so much, Chris. And it's truly a gre...</td>\n",
       "      <td>https://www.ted.com/talks/al_gore_on_averting_...</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>[{'id': 243, 'hero': 'https://pe.tedcdn.com/im...</td>\n",
       "      <td>['alternative energy', 'cars', 'climate change...</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>Design and discovery,A one-man world summit,A ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Music: \"The Sound of Silence,\" Simon &amp; Garfun...</td>\n",
       "      <td>https://www.ted.com/talks/david_pogue_says_sim...</td>\n",
       "      <td>David Pogue</td>\n",
       "      <td>[{'id': 1725, 'hero': 'https://pe.tedcdn.com/i...</td>\n",
       "      <td>['computers', 'entertainment', 'interface desi...</td>\n",
       "      <td>Simplicity sells</td>\n",
       "      <td>A one-man world summit,Nerdcore comedy,Cool tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you're here today — and I'm very happy that...</td>\n",
       "      <td>https://www.ted.com/talks/majora_carter_s_tale...</td>\n",
       "      <td>Majora Carter</td>\n",
       "      <td>[{'id': 1041, 'hero': 'https://pe.tedcdn.com/i...</td>\n",
       "      <td>['MacArthur grant', 'activism', 'business', 'c...</td>\n",
       "      <td>Greening the ghetto</td>\n",
       "      <td>How students of color confront impostor syndro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>About 10 years ago, I took on the task to teac...</td>\n",
       "      <td>https://www.ted.com/talks/hans_rosling_shows_t...</td>\n",
       "      <td>Hans Rosling</td>\n",
       "      <td>[{'id': 2056, 'hero': 'https://pe.tedcdn.com/i...</td>\n",
       "      <td>['Africa', 'Asia', 'Google', 'demo', 'economic...</td>\n",
       "      <td>The best stats you've ever seen</td>\n",
       "      <td>Religions and babies,The good news of the deca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          transcript  \\\n",
       "0  Good morning. How are you?(Laughter)It's been ...   \n",
       "1  Thank you so much, Chris. And it's truly a gre...   \n",
       "2  (Music: \"The Sound of Silence,\" Simon & Garfun...   \n",
       "3  If you're here today — and I'm very happy that...   \n",
       "4  About 10 years ago, I took on the task to teac...   \n",
       "\n",
       "                                                 url   main_speaker  \\\n",
       "0  https://www.ted.com/talks/ken_robinson_says_sc...   Ken Robinson   \n",
       "1  https://www.ted.com/talks/al_gore_on_averting_...        Al Gore   \n",
       "2  https://www.ted.com/talks/david_pogue_says_sim...    David Pogue   \n",
       "3  https://www.ted.com/talks/majora_carter_s_tale...  Majora Carter   \n",
       "4  https://www.ted.com/talks/hans_rosling_shows_t...   Hans Rosling   \n",
       "\n",
       "                                       related_talks  \\\n",
       "0  [{'id': 865, 'hero': 'https://pe.tedcdn.com/im...   \n",
       "1  [{'id': 243, 'hero': 'https://pe.tedcdn.com/im...   \n",
       "2  [{'id': 1725, 'hero': 'https://pe.tedcdn.com/i...   \n",
       "3  [{'id': 1041, 'hero': 'https://pe.tedcdn.com/i...   \n",
       "4  [{'id': 2056, 'hero': 'https://pe.tedcdn.com/i...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['children', 'creativity', 'culture', 'dance',...   \n",
       "1  ['alternative energy', 'cars', 'climate change...   \n",
       "2  ['computers', 'entertainment', 'interface desi...   \n",
       "3  ['MacArthur grant', 'activism', 'business', 'c...   \n",
       "4  ['Africa', 'Asia', 'Google', 'demo', 'economic...   \n",
       "\n",
       "                             title  \\\n",
       "0      Do schools kill creativity?   \n",
       "1      Averting the climate crisis   \n",
       "2                 Simplicity sells   \n",
       "3              Greening the ghetto   \n",
       "4  The best stats you've ever seen   \n",
       "\n",
       "                                       similar_talks  \n",
       "0  A one-man world summit,How to run a company wi...  \n",
       "1  Design and discovery,A one-man world summit,A ...  \n",
       "2  A one-man world summit,Nerdcore comedy,Cool tr...  \n",
       "3  How students of color confront impostor syndro...  \n",
       "4  Religions and babies,The good news of the deca...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"HIV and flu -- the vaccine strategy,Lessons from the 1918 flu,How we'll stop polio for good,The case for optimism\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['similar_talks'][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sivakumar\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: ['wikipedia', 'not', 'images', 'page', 'notre'],\n",
       " 1: ['mockingbird', 'mockingbirds', 'juanito', 'mimus', 'vente'],\n",
       " 2: ['not', 'one', 'want', 'people', 'cannot'],\n",
       " 3: ['molas', 'mola', 'not', 'laughter', 'think'],\n",
       " 4: ['wk', 'kasungu', 'mala', 'kamkwamba', 'da'],\n",
       " 5: ['clonie', 'eminem', 'spector', 'ie', 'huggable'],\n",
       " 6: ['not', 'people', 'one', 'like', 'would'],\n",
       " 7: ['not', 'like', 'one', 'laughter', 'people'],\n",
       " 8: ['halter', 'vie', 'lui', 'mots', 'rachelle'],\n",
       " 9: ['kiteflyers', 'hewerdine', 'not', 'music', 'would']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "n_topics = 10\n",
    "lda = LatentDirichletAllocation(n_components=n_topics,random_state=0)\n",
    "\n",
    "topics = lda.fit_transform(matrix)\n",
    "top_n_words = 5\n",
    "t_words, word_strengths = {}, {}\n",
    "for t_id, t in enumerate(lda.components_):\n",
    "    t_words[t_id] = [tfidf.get_feature_names()[i] for i in t.argsort()[:-top_n_words - 1:-1]]\n",
    "    word_strengths[t_id] = t[t.argsort()[:-top_n_words - 1:-1]]\n",
    "t_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['not', 'laughter', 'know', 'people', 'like'],\n",
       " 1: ['data', 'actually', 'computer', 'like', 'information'],\n",
       " 2: ['music', 'applause', 'sound', 'guitar', 'play'],\n",
       " 3: ['not', 'people', 'world', 'countries', 'africa'],\n",
       " 4: ['cancer', 'cells', 'patients', 'disease', 'cell'],\n",
       " 5: ['water', 'earth', 'planet', 'ocean', 'universe'],\n",
       " 6: ['women', 'men', 'girls', 'not', 'woman'],\n",
       " 7: ['city', 'cities', 'building', 'design', 'buildings'],\n",
       " 8: ['brain', 'neurons', 'brains', 'cells', 'human'],\n",
       " 9: ['kids', 'school', 'children', 'education', 'students']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "n_topics = 10\n",
    "nmf = NMF(n_components=n_topics,random_state=0)\n",
    "\n",
    "topics = nmf.fit_transform(matrix)\n",
    "top_n_words = 5\n",
    "t_words, word_strengths = {}, {}\n",
    "for t_id, t in enumerate(nmf.components_):\n",
    "    t_words[t_id] = [tfidf.get_feature_names()[i] for i in t.argsort()[:-top_n_words - 1:-1]]\n",
    "    word_strengths[t_id] = t[t.argsort()[:-top_n_words - 1:-1]]\n",
    "t_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic distribution for document #6: \n",
      " [[0.11322825 0.         0.         0.         0.         0.\n",
      "  0.038167   0.         0.         0.02529564]]\n",
      "Relevant topics for document #6: \n",
      " [0 6 9]\n",
      "\n",
      "Transcript:\n",
      " On September 10 the morning of my seventh birthday I came downstairs to the kitchen where my mother was washing the dishes and my father was reading the paper or something and I sort of presented myself to them in the doorway and they said Hey happy birthday And I said I am seven And my father smiled and said Well you know what that means do not you And I said Yeah that I am going to have a party and a cake and get a lot of presents And my dad said Well yes But more importantly being seven means ...\n",
      "\n",
      "True tags from ted_main.csv: \n",
      " 6    ['Christianity', 'God', 'atheism', 'comedy', '...\n",
      "Name: tags, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([\n",
    "    ('tfidf', tfidf),\n",
    "    ('nmf', nmf)\n",
    "])\n",
    "\n",
    "document_id = 6\n",
    "t = pipe.transform([transcript['transcript_clean'].iloc[document_id]]) \n",
    "print('Topic distribution for document #{}: \\n'.format(document_id),t)\n",
    "print('Relevant topics for document #{}: \\n'.format(document_id),np.where(t>0.01)[1])\n",
    "print('\\nTranscript:\\n',transcript['transcript_clean'].iloc[document_id][:500],'...')\n",
    "\n",
    "talk = ted[ted['url']==transcript['url'].iloc[document_id]]\n",
    "\n",
    "#talk = data[data['url'].iloc[document_id]]\n",
    "print('\\nTrue tags from ted_main.csv: \\n',talk['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
